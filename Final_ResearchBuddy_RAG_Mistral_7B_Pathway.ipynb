{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDT8CSI81MG1",
        "outputId": "8fbbf047-99b8-44f5-859c-74f13d6d78cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei_N_jlUvWDV",
        "outputId": "325a9ff2-64df-4d17-ead9-e04874953d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.82-cp310-cp310-linux_x86_64.whl size=2815258 sha256=18f22d685be690eba7ef98b8cf94937697e08efb1ed247286848e3ec6a7aca91\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/da/5a/272c969ba31c678e6bee2543f3be4dfa67d0feb36ed6f94c01\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: llama-cpp-python\n",
            "Successfully installed llama-cpp-python-0.2.82\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.12)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.84)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.7)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.12)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.84)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (2.7.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (2.18.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: pathway in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.9.5)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (8.1.7)\n",
            "Requirement already satisfied: geopy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.4.1)\n",
            "Requirement already satisfied: h3>=3.7.6 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.7.7)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.25.2)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.2.2)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.0.4)\n",
            "Requirement already satisfied: sqlglot==10.6.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (10.6.1)\n",
            "Requirement already satisfied: pyarrow>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (14.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.31.0)\n",
            "Requirement already satisfied: python-sat>=0.1.8.dev0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.8.dev13)\n",
            "Requirement already satisfied: beartype<0.16.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (0.15.0)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (13.7.1)\n",
            "Requirement already satisfied: diskcache>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (5.6.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.2.1)\n",
            "Requirement already satisfied: boto3>=1.26.76 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.34.141)\n",
            "Requirement already satisfied: google-api-python-client>=2.108.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.136.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.12.2)\n",
            "Requirement already satisfied: panel>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.3.8)\n",
            "Requirement already satisfied: jupyter-bokeh>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.0.5)\n",
            "Requirement already satisfied: jmespath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.0.1)\n",
            "Requirement already satisfied: aiohttp-cors>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (0.7.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.25.0)\n",
            "Requirement already satisfied: fs>=2.4.16 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.4.16)\n",
            "Requirement already satisfied: async-lru>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.0.4)\n",
            "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.3)\n",
            "Requirement already satisfied: google-cloud-pubsub>=2.21.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.21.5)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (from pathway) (3.21.0)\n",
            "Requirement already satisfied: pydantic~=2.7.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.7.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (4.0.3)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.141 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.26.76->pathway) (1.34.141)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.26.76->pathway) (0.10.2)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (1.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (67.7.2)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (1.16.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy>=2.4.0->pathway) (2.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.16.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.51.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.64.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (3.20.3)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (0.13.1)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.48.2)\n",
            "Requirement already satisfied: bokeh==3.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (3.3.4)\n",
            "Requirement already satisfied: ipywidgets==8.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (8.1.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (1.2.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (24.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (2024.6.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.11)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (7.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.63.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.22.0->pathway) (0.46b0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2024.1)\n",
            "Requirement already satisfied: param<3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.1.1)\n",
            "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.6)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (4.66.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (6.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.7.0->pathway) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.7.0->pathway) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (2024.6.2)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->pathway) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (3.5.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.7.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->pathway) (1.14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery->pathway) (1.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=2.108.0->pathway) (3.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.22.0->pathway) (3.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.3.1->pathway) (0.1.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.3.1->pathway) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.3.1->pathway) (1.0.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.47)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.13)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.43.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.6.2)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: llama-cpp-python in /usr/local/lib/python3.10/dist-packages (0.2.82)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install --prefer-binary pathway\n",
        "# !pip install torch\n",
        "!pip install sentence_transformers\n",
        "# !pip install faiss-cpu\n",
        "!pip install huggingface-hub\n",
        "!pip install pypdf\n",
        "!pip -q install accelerate\n",
        "!pip install llama-cpp-python\n",
        "!pip -q install git+https://github.com/huggingface/transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8D6s3uMHv-NG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6301ece8-7168-4198-db43-8d2cffb0a974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pathway[xpack-llm] in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (3.9.5)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (8.1.7)\n",
            "Requirement already satisfied: geopy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (2.4.1)\n",
            "Requirement already satisfied: h3>=3.7.6 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (3.7.7)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (1.25.2)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (1.2.2)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (2.0.4)\n",
            "Requirement already satisfied: sqlglot==10.6.1 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (10.6.1)\n",
            "Requirement already satisfied: pyarrow>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (14.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (2.31.0)\n",
            "Requirement already satisfied: python-sat>=0.1.8.dev0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (1.8.dev13)\n",
            "Requirement already satisfied: beartype<0.16.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (0.15.0)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (13.7.1)\n",
            "Requirement already satisfied: diskcache>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (5.6.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (1.2.1)\n",
            "Requirement already satisfied: boto3>=1.26.76 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (1.34.141)\n",
            "Requirement already satisfied: google-api-python-client>=2.108.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (2.136.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (4.12.2)\n",
            "Requirement already satisfied: panel>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (1.3.8)\n",
            "Requirement already satisfied: jupyter-bokeh>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (4.0.5)\n",
            "Requirement already satisfied: jmespath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (1.0.1)\n",
            "Requirement already satisfied: aiohttp-cors>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (0.7.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (1.25.0)\n",
            "Requirement already satisfied: fs>=2.4.16 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (2.4.16)\n",
            "Requirement already satisfied: async-lru>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (2.0.4)\n",
            "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (3.3)\n",
            "Requirement already satisfied: google-cloud-pubsub>=2.21.1 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (2.21.5)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (3.21.0)\n",
            "Requirement already satisfied: pydantic~=2.7.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (2.7.4)\n",
            "Collecting openai>=1.6 (from pathway[xpack-llm])\n",
            "  Downloading openai-1.35.10-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting litellm>=1.0 (from pathway[xpack-llm])\n",
            "  Downloading litellm-1.41.13-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cohere~=5.1.0 (from pathway[xpack-llm])\n",
            "  Downloading cohere-5.1.8-py3-none-any.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.3/145.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken>=0.5 (from pathway[xpack-llm])\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core==0.1.30 (from pathway[xpack-llm])\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain==0.1.11 (from pathway[xpack-llm])\n",
            "  Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-core~=0.10.0 (from pathway[xpack-llm])\n",
            "  Downloading llama_index_core-0.10.53.post1-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-readers-pathway~=0.1.0 (from pathway[xpack-llm])\n",
            "  Downloading llama_index_readers_pathway-0.1.3-py3-none-any.whl (3.1 kB)\n",
            "Collecting llama-index-retrievers-pathway~=0.1.0 (from pathway[xpack-llm])\n",
            "  Downloading llama_index_retrievers_pathway-0.1.3-py3-none-any.whl (3.3 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0 in /usr/local/lib/python3.10/dist-packages (from pathway[xpack-llm]) (8.4.2)\n",
            "Collecting instructor==1.2.6 (from pathway[xpack-llm])\n",
            "  Downloading instructor-1.2.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor==1.2.6->pathway[xpack-llm]) (0.16)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor==1.2.6->pathway[xpack-llm]) (2.18.4)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor==1.2.6->pathway[xpack-llm]) (0.12.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.11->pathway[xpack-llm]) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.11->pathway[xpack-llm]) (2.0.31)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.11->pathway[xpack-llm]) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.11->pathway[xpack-llm]) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.11->pathway[xpack-llm]) (1.33)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain==0.1.11->pathway[xpack-llm])\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.11->pathway[xpack-llm])\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.11->pathway[xpack-llm]) (0.1.84)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.1.30->pathway[xpack-llm]) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core==0.1.30->pathway[xpack-llm])\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway[xpack-llm]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway[xpack-llm]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway[xpack-llm]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway[xpack-llm]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway[xpack-llm]) (1.9.4)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.141 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.26.76->pathway[xpack-llm]) (1.34.141)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.26.76->pathway[xpack-llm]) (0.10.2)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere~=5.1.0->pathway[xpack-llm])\n",
            "  Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.21.2 (from cohere~=5.1.0->pathway[xpack-llm])\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-requests<3.0.0.0,>=2.31.0.20240311 (from cohere~=5.1.0->pathway[xpack-llm])\n",
            "  Downloading types_requests-2.32.0.20240622-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway[xpack-llm]) (1.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway[xpack-llm]) (67.7.2)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway[xpack-llm]) (1.16.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy>=2.4.0->pathway[xpack-llm]) (2.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway[xpack-llm]) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway[xpack-llm]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway[xpack-llm]) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway[xpack-llm]) (2.16.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway[xpack-llm]) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.51.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway[xpack-llm]) (1.64.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway[xpack-llm]) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway[xpack-llm]) (3.20.3)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway[xpack-llm]) (0.13.1)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway[xpack-llm]) (1.48.2)\n",
            "Requirement already satisfied: bokeh==3.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (3.3.4)\n",
            "Requirement already satisfied: ipywidgets==8.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (8.1.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (1.2.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (9.4.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (2024.6.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (3.0.11)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.0->pathway[xpack-llm]) (7.1.0)\n",
            "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm>=1.0->pathway[xpack-llm])\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.2.0 (from litellm>=1.0->pathway[xpack-llm])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm>=1.0->pathway[xpack-llm]) (0.19.1)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core~=0.10.0->pathway[xpack-llm]) (1.2.14)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core~=0.10.0->pathway[xpack-llm])\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core~=0.10.0->pathway[xpack-llm]) (2023.6.0)\n",
            "Collecting llama-cloud<0.0.7,>=0.0.6 (from llama-index-core~=0.10.0->pathway[xpack-llm])\n",
            "  Downloading llama_cloud-0.0.6-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core~=0.10.0->pathway[xpack-llm]) (1.6.0)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core~=0.10.0->pathway[xpack-llm]) (3.8.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core~=0.10.0->pathway[xpack-llm]) (4.66.4)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core~=0.10.0->pathway[xpack-llm]) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core~=0.10.0->pathway[xpack-llm]) (1.14.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.6->pathway[xpack-llm]) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.6->pathway[xpack-llm]) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway[xpack-llm]) (1.63.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway[xpack-llm]) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway[xpack-llm]) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.22.0->pathway[xpack-llm]) (0.46b0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway[xpack-llm]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway[xpack-llm]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway[xpack-llm]) (2024.1)\n",
            "Requirement already satisfied: param<3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway[xpack-llm]) (2.1.1)\n",
            "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway[xpack-llm]) (3.0.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway[xpack-llm]) (3.6)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway[xpack-llm]) (3.0.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway[xpack-llm]) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway[xpack-llm]) (0.4.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway[xpack-llm]) (6.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.7.0->pathway[xpack-llm]) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway[xpack-llm]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway[xpack-llm]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway[xpack-llm]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway[xpack-llm]) (2024.6.2)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->pathway[xpack-llm]) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway[xpack-llm]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway[xpack-llm]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway[xpack-llm]) (3.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.5->pathway[xpack-llm]) (2024.5.15)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway[xpack-llm]) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway[xpack-llm]) (2.7.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.11->pathway[xpack-llm]) (3.21.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway[xpack-llm]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway[xpack-llm]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway[xpack-llm]) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery->pathway[xpack-llm]) (1.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=2.108.0->pathway[xpack-llm]) (3.1.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.21.2->cohere~=5.1.0->pathway[xpack-llm])\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.21.2->cohere~=5.1.0->pathway[xpack-llm])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.0->pathway[xpack-llm]) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh==3.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.11->pathway[xpack-llm]) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.0->pathway[xpack-llm]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.0->pathway[xpack-llm]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.0->pathway[xpack-llm]) (0.18.1)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain==0.1.11->pathway[xpack-llm])\n",
            "  Downloading langchain_community-0.0.37-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.35-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.0.30-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.11->pathway[xpack-llm]) (3.10.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.3.1->pathway[xpack-llm]) (0.1.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.11->pathway[xpack-llm]) (3.0.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.9.0->instructor==1.2.6->pathway[xpack-llm]) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core~=0.10.0->pathway[xpack-llm]) (1.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.3.1->pathway[xpack-llm]) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.3.1->pathway[xpack-llm]) (1.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm>=1.0->pathway[xpack-llm]) (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.0->pathway[xpack-llm]) (3.15.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (3.0.47)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (4.9.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway[xpack-llm]) (0.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway[xpack-llm]) (0.2.13)\n",
            "Installing collected packages: dirtyjson, types-requests, python-dotenv, packaging, h11, fastavro, tiktoken, httpcore, jsonschema, httpx, openai, llama-cloud, langchain-core, cohere, llama-index-core, litellm, langchain-text-splitters, langchain-community, instructor, llama-index-retrievers-pathway, llama-index-readers-pathway, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.2\n",
            "    Uninstalling jsonschema-4.19.2:\n",
            "      Successfully uninstalled jsonschema-4.19.2\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.2.12\n",
            "    Uninstalling langchain-core-0.2.12:\n",
            "      Successfully uninstalled langchain-core-0.2.12\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.2.2\n",
            "    Uninstalling langchain-text-splitters-0.2.2:\n",
            "      Successfully uninstalled langchain-text-splitters-0.2.2\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.2.7\n",
            "    Uninstalling langchain-community-0.2.7:\n",
            "      Successfully uninstalled langchain-community-0.2.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.2.7\n",
            "    Uninstalling langchain-0.2.7:\n",
            "      Successfully uninstalled langchain-0.2.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cohere-5.1.8 dirtyjson-1.0.8 fastavro-1.9.5 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 instructor-1.2.6 jsonschema-4.23.0 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.2 litellm-1.41.13 llama-cloud-0.0.6 llama-index-core-0.10.53.post1 llama-index-readers-pathway-0.1.3 llama-index-retrievers-pathway-0.1.3 openai-1.35.10 packaging-23.2 python-dotenv-1.0.1 tiktoken-0.7.0 types-requests-2.32.0.20240622\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_huggingface'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7cfcd1149093>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunnablePassthrough\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_huggingface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_store\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVectorStoreServer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_huggingface'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install pathway[xpack-llm]\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "# Necessary Pathway imports\n",
        "import pandas as pd\n",
        "import pathway as pw\n",
        "from pathway.stdlib.indexing import default_vector_document_index\n",
        "from pathway.xpacks.llm import embedders\n",
        "from pathway.xpacks.llm.question_answering import answer_with_geometric_rag_strategy_from_index\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from pathway.xpacks.llm.vector_store import VectorStoreServer\n",
        "from langchain_community.vectorstores import PathwayVectorClient\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEXsAyTZxBu7"
      },
      "outputs": [],
      "source": [
        "#load pdf files\n",
        "loader = PyPDFDirectoryLoader(\"/content/drive/MyDrive/Data\")\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMtudY08xzRO",
        "outputId": "83437f01-a1d7-4506-cc61-93d54e1cee99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 0}, page_content=\"Identifying Parking Lot Occupancy with YOLOv5  \\n \\nManato Ogawa, Tomer Arnon# and Edward Gruber1# \\n \\n1Eastchester High School  \\n#Advisor  \\n \\nABSTRACT  \\n \\nWith the increasing need for efficient parking space management and growing population, the application of artificial \\nintelligence (AI) in occupancy detection has become a topic of significant interest. This paper explores the effective-\\nness and reliability  of the YOLO (You Only Look Once) object detection algorithm in differentiating between occu-\\npied and empty parking spots. Moreover, it analyzes the impact of the number of training epochs on the overall accu-racy of the AI model. The study utilizes the YOLO  algorithm due to its speed and accuracy which makes the training \\nprocess highly efficient. A custom dataset of 135 images was created and annotated for training purposes. The primary objective of this experiment is to demonstrate the way how AI models can successfully distinguish between occupied \\nand empty parking spaces. By addressing the capabilities of YOLO in occupancy detection, this research aims to contribute to the growing interest in AI applications for efficient parking space management and its i mplications in \\ntackling real -world challenges.  \\n \\nIntroduction  \\n The rapid urbanization and population growth in recent years have led to an increasing demand for efficient parking \\nmanagement systems [1, 2]. Traditional manual monitoring approaches such as ticket booths have proven to be both \\ntime-consuming and imperfect [3]. Consequently, there is a growing need for automated system capable of real -time \\noccupancy detection where it can accurately determine the occupancy status of individual parking spaces [4, 5]. This research paper aims to address this need by proposing an AI -based solution that analyzes images of parking lots to \\nidentify whether each slot is occupied or vacant [23]. To achieve this, the research utilizes the advanced real -time \\nobject detection algorithm, YOLOv5 (You Only Look Once version 5) [22]. YOLOv5 is well -suited for this task due \\nto its high accuracy and efficiency in detecting objects in images and videos in real -time. It performs object detection \\nin a single forward pass of the neural network, making it faster than traditional methods. The primary objective of this \\nresearch is to develop an AI model capable of binary classification, categorizing each parking slot as either occupied \\nor vacant. The AI model is trained using a supervised learning approach where labeled images of parking spaces are \\nused as training data. These images are captured from various angles and under different lighting conditions, and each \\nparking spot is annotated with its ground truth occupancy status. The output of performing object detection methods \\nbased on a trained AI model includes a set of labels indicating the occupancy status of each parking space in the input \\nimage accompanied by a confidence score representing the algorithm's certainty in its classif ication. Additionally, \\ngraphs representing the train/obj_loss or metrics are produced to analyze the training performance over each epoch. By effectively determining the occupancy status of parking spaces through computer vision and machine learning \\ntechni ques, the proposed system has a potential to significantly improve current parking management. This improve-\\nment can lead to enhanced efficiency, reduced congestion, and an overall improved user experience. The subsequent sections of this paper will elabora te on the methodology, experimental results, and potential applications of this AI -\\nbased parking space occupancy detection system.  \\n \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n1\\n\"), Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 1}, page_content=\"Dataset  \\n \\nThe dataset utilized in this project was custom -made by capturing pictures of parking spaces in the author's neighbor-\\nhood. It was specifically designed for parking lot occupancy detection consisting predominantly of images with or without cars parked at parking spaces. The dataset consists of 135 images in JPEG format with a 12.2- megapixel \\nresolution captured using an iPhone. To label the images, the LILIN AI labeling tool was employed [20]. Each image is labeled to indicate whether the parking space is empty or occupied. The images in the dataset were captured from \\nvarious angles and perspectives, resulting in a diverse collection of parking lot scenarios. The diversity is crucial for \\ntraining an AI model that can generalize effectively to real -world parking lots. Before training the AI model, several \\ndata preprocessing steps were performed. Firstly, all images were resized to a standardized size of 4032x3024 pixels. This uniformity ensures that the model analyzes images of the same dimensions which in turn,  enhances its accuracy. \\nSecondly, data augmentation techniques were applied to improve the model's performance. Techniques such as chang-ing angles of the camera and capturing pictures of both occupied and empty parking spaces at the same location were \\nempl oyed to create additional variations in the dataset. Next, the dataset's pixel values were normalized to a range of \\n0 to 1 [21]. Normalization helps equalize the importance of each variable in the dataset as it prevents any single variable from disproporti onately influencing the model's performance due to large numerical values. To evaluate the \\nAI model's performance, the dataset was split into training and validation subsets without shuffling at the start. The training set contains 90% of the total images,  while the remaining 10% forms the validation set [7]. A visual repre-\\nsentation of the parking lot scenes and the varying perspectives captured is attached below.   \\n \\n \\nFigure 1.  In each image, there are yellow and orange bounding boxes. The yellow boxes represent empty spaces \\nwhereas the orange boxes represent occupied spaces . \\n \\nThe dataset used in this research serves as a valuable resource for training the AI model to accurately determine \\nparking space occupancy from images. The subsequent sections will explain details of the training methodology, \\nexperimental results, and the m odel's potential real- world applications.  \\n \\nMethodology/Models \\n \\nYOLOv5 (You Only Look Once), a popular and effective object detection algorithm, was used for this project [22]. \\nPython code from the YOLOv5 package was executed in a Google Colab notebook to create and train the model from \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n2\\n\"), Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 2}, page_content='the custom dataset. The YOLO algorithm is a deep learning -based object detection method known for its real -time \\ndetection capabilities [8][9][10]. It performs both object localization (identifying the location of one or more objects \\nin an image and drawing  a bounding box around it) and classification (naming the bounding boxes) simultaneously. \\nYOLO uses Convolutional Neural Networks (CNN) to detect images.  Convolutional Neural Networks (CNN) is a neural network that looks at a whole group of pixels in an image [11][12]. This allows for feature learning where the \\nmodel can analyze the image thoroughly allowing it to spot any features that will help to make a prediction. The \\ndarknet architecture of YOLOv5 supports various types of layers including CNN and pooling layers. CNNs employ \\nconvolutional layers to extract relevant features from the images such as edges, textures, and shapes associated with \\nparking spaces. Pooling layers in the CNN reduce the spatial dimensions of the feature map by combining the outputs \\nof neuron clusters at the previous layer into a single neuron in the next layer allowing for the model to intake the most \\nuseful information and leave out insignificant features in an image.  \\nDuring the training process, the YOLO model used loss functions to improve accuracy. YOLOv5’s loss \\nfunction is composed of three parts: box_loss, obj_loss, and cls_loss [13][6]. These loss functions are applied to max-\\nimize the objective of mean average precision, a measurement used to measure the performance of computer vision \\nmodels [14]. After every epoch, the model is tested on the validation dataset and an overall loss value is calculated. \\nThe training ends when the number of epochs allotted (300 and 50) is completed.  In order to detect objects, YOLO \\ndivides the input image into a n x n grid and draws bounding boxes along with probabilities of classified objects for \\neach grid cell. This approach allows for efficient and accurate object detection.   Anch or boxes are another important \\ncomponent in the training of the model [15]. Anchor boxes are a set of predefined bounding boxes of a certain height and width.  The size of the anchor boxes is typically based on the object size in the training dataset where  bigger \\nobjects in a training image would result in bigger anchor boxes. These boxes are tiled across the images and  capture \\nthe specific object classes to be detected which in this case is empty or occupied parking spaces.  \\nOnce the anchor boxes are scattered across the image, a metric such as Intersection Over Union (IoU) is used \\nto determine the probability of a certain object in an image. Intersection Over Union is a number that quantifies the \\ndegree of overlap between two  boxes [16].   The equation to compute the IoU is the area of overlap of both bounding \\nboxes over the area of union (the ground truth bounding box area + predicted bounding box area - an area of intersec-\\ntion of both bounding boxes). A number between 0 and 1 is calculated where a higher value indicates a greater overlap \\narea and a higher accuracy.  \\nAt this point, the model has many bounding boxes shown on the image which makes the image messy and \\nunorganized. Therefore, Non -Maximum Suppression (NMS) method is used to help combine bouncing boxes, but \\nalso remove bounding boxes that have an IoU value lower than the NMS threshold [17][18]. NMS selects a single \\nbounding box with the highest confidence score and combines other bounding boxes that have a high overlap with it. \\nNMS helps in reducing duplicate detections and improves the final output by the mo del.  \\nThe model learning procedure consists of the creation of the dataset, preprocessing the data, splitting the \\ndataset, and training the model. As previously stated, I created my own dataset. This way, I ensured that the model \\nwas using the most accurate imag es to train with minimal human error. Once all necessary files were properly uploaded \\ninto the C olab notebook, I started the training for 50 and 300 epochs. It took around 2- 3 hours for both to finish, and \\nI downloaded all the results produced by the model. Once the training process was completed for both models, I \\nrecorded the different predictions produced.  \\n \\nResults and Discussion  \\n Once I trained the model, I went outside and took a video of a car going in and out of a parking space to see if the \\nmodel could properly detect the empty and occupied parking spaces. The model trained for 300 epochs performed \\nsignificantly better than the  model with 50 epochs when tested on the video and images.  \\n \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n3\\n'), Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 3}, page_content=\".  \\nFigure 2 .  Precision and recall graphs of 50 epoch \\nmodel    Figure 3 . Precision and recall graphs of 300 epoch \\nmodel  \\nFigures 2 and 3 show the precision and recall metrics of each model. Recall measures the proportion of \\npositive instances (occupied parking spaces) that are correctly identified as positive by the model [19]. In this case, a \\nrecall measures a number of occupied parking spaces correctly classified by the model over total number of actual \\noccupied parking spaces.  It quantifies the model's ability to avoid false negatives. As shown in the graphs, the model \\nwith 300 epochs had an average recall of about 0.7 whereas the model with 50 epochs had an average recall of about \\n0.55. The higher recall indicated by Figure 3 means that the model was more effective at identifying occupied parking \\nspaces while minimizing the instances where they were incorrectly labeled as  vacant . Precision measures the propor-\\ntion of instances identified as positive by the model that are actually true positives. [19] In this case, the precision measures number of occupied parking spaces correctly classified over total number of occupied parking spaces clas-\\nsified by the model which may include number of empty parking spaces incorrectly classified.  It quantifies the model's \\nability to avoid false positives. As shown in the graphs, the model with 300 epochs had an average precision of about \\n0.8 whereas the model with 50 epochs had an average precision of about 0.6. The higher precision indicated by Figure \\n3 means that the model has a low rate of incorrectly labeling vacant spaces as occupied. Essentially, the graph demon-strates that the model w ith 300 epochs is more accurate than the model with 50 epochs. In addition to precision and \\nrecall measurement, the confusion matrix of both models (Figure 4 and 5) also showed interesting results indicating the model with 300 epochs was more accurate.  \\n Figures  4 and 5  are the confusion matrices of each model. Confusion matrices use True Positives (TP; In-\\nstances when predicted as occupied and is actually occupied), False Positives (FP; Instances when predicted as occu-pied although they are actually vacant, instances when predicted as background although they are actually vacant, or \\ninstances when predicted as empty although they are actually background), False Negatives (FN; Instances when \\npredicted as vacant although they are actually occupied, instances when predicted as background although they are \\nactually occupied, or instances when predicted as occupied although they are actually background), and True Nega-\\ntives (TN; Instances when predicted as vacant and they are actually vacant) to represent how well  the model performed.  \\n  \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n4\\n\"), Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 4}, page_content=' \\n \\nFigure 4 . Confusion matrix of 50 epoch model   Figure 5 . Confusion matrix of 300 epoch model  \\n   \\nThe numbers in the confusion matrix represent the model’s accuracy of its prediction. For example, in Figure \\n5, 0.66 represents the model predicted correctly occupied for 66% of time, whereas 0.34 represents the model predicted \\nbackground 34% of time although it was occupied. Figure 4 shows the 50 epochs model correctly predicted occupied \\nspaces for 13 %, whereas the 300 epochs model correctly predicted occupied for 66% and empty for 58%. In addition, \\neither model did not classify empty as occupied or vice versa. Both models worked to a certain extent that they were able to recognize properly if parking spaces were occupied or not. However, in Figure 4, it was understood that the \\nmodel with 50 epochs barely recognized the parking space itself. As shown, the model, for the most part, was not able \\nto identify the parking space based on the number in the graph as sum of the values where the model incorrectly \\npredicted background (1.87 = 0.87+1) over total value (2 = 0.13 +0.87+1.0) is very high whereas it is other way around for a situation where the model correctly predicted either an empty or occupied (0.13 over 2). This indicates that the \\nmodel had a low capability to recognize parking spaces where in most of the predictions being classified as “back-\\nground”.  \\nHowever, the model with 300 epochs performed much better. Firstly, the TP and TN values were 0.66 and \\n0.58 respectively. This means that the model predicted 1.24 (0.66+0.58; sum of the values where the model correctly \\npredicted the parking space occupancy)  out of 3 (0.66+0.34+0.58+0.42+0.08+0.92; sum of the TP (0.66), TN (0.58), \\nFP (empty(0.42), background(0.92)), and FN (occupied(0.34), background(0.08)) values) which is a significant im-provement compared to the model with 50 epochs. However, interestingly, the AI model predicted 0.92 (value where \\nthe model predicted an empty parking space when in reality it was a background) out of 1 (0.92 + 0.08: total value for \\nbackground). A possible explanation is that the model interprets any image of a car as an occupied space, and anything \\nelse as empty. Since the bounding boxes setup in the training data were large, the model might have incorrectly learned \\nthat a frame without a car is an empty space. This means that the model may not have spotted parking space feat ures \\nsuch as two white lines or the numbers that indicate a parking spot.  In addition, 0.08 out of 1 false positive which means the model predicted occupied when in reality it was background, could be explained by cars being in the back-\\nground that were pi cked up by the model, but were not annotated.  \\n \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n5\\n'), Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 5}, page_content=' \\n Figure 6 .  mAP graph of 50 epoch model        Figure 7. mAP graph of 300 epoch model  \\n \\n \\n Figure 8. Precision -Recall graph of 50 epoch model  Figure 9 .  Precision -Recall graph of 300 epoch model  \\n  \\nThe graphs in Figures  8 and 9 represent the Mean Average Precision (mAP) of each model. Mean average \\nprecision is a commonly used evaluation metric in object detection tasks [14]. It measures the accuracy of an object \\ndetection model by considering both precision and recall. The Precision -Recall curve is used to compute the mean \\nAverage Precision. As shown in Figures 6 and 7, both models have fluctuations, but overall mAP increases towards the end. The mAP for the 50 epochs model is about 0.6 at the end of the training, whereas  the mAP for the 300 epochs \\nmodel is about 0.75. A higher mAP indicates better performance, meaning the 300 epochs model is capable of more accurately identifying parking spots within the parking lot image or video. This statement corresponds to the data \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n6\\n'), Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 6}, page_content='represented in Figures 2 and 3, as the 50 epochs model had a lower precision and recall value than the 300 epochs \\nmodel, as well as Figures 4 and 5 where the matrices showed improved accuracy of model with the 300 epochs com-\\npared to the 50 epochs.  \\n \\n \\n \\nFigure 1 0 : Results of video input for 50/300 epoch models with & without car  \\n  Lastly, the images shown in Figure 10 are the predictions made by both models from a video of a car entering \\nand leaving a parking space. As previously explained, the 300 epochs model had a significantly higher accuracy than the 50 epochs model. Figures 10A and 10C represent the predictions made by the 50 epochs model, and it is clear that \\nthe model was not able to accurately predict anything which corresponds to the confusion matrix which predicted \\nmostly everything as “background”. However, Figures 10B and 10D showed a totally different result. In both images, \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n7\\n'), Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 7}, page_content=\"it was clear that the model with 300 epochs was able to predict all the parking spots perfectly with most having a \\nrelatively high confidence value. This result also corresponds to the metrics collected where prediction  for parking lot \\noccupancies using a model with 300 epochs is significantly better than the model with 50 epochs.  \\n \\nConclusion  \\n \\nIn this research paper, the objective was to analyze the effectiveness of the YOLO model in accurately predicting the \\noccupancy of parking spaces based on a custom -made dataset containing images of empty and occupied parking spaces \\nso that it can be used for automated system capable of real -time parking occupancy detection.  The model trained with \\n50 epochs achieved an accuracy of approximately 6.5%, while the model trained with 300 epochs achieved an accu-\\nracy of about 41.3%. Although both models exhibited s ome level of accuracy, their performance fell short of being \\nsuitable for integration into automated parking systems.  \\nThe outcome of this study gives us hints for several factors that may have caused limited success of the \\nmodels. One possibility is that the models were not trained for a sufficient number of epochs as evidence showed significant improvement observed by increasing the number of epochs from 50 to 300. Additionally, the large image \\nsize in the dataset might have hindered the models' learning capabilities, prompting consideration for using resized \\nimages in future experiments. The dataset's lack of variety, particularly in terms of different angles and perspectives \\nof parking spaces, could have limited the models' ability to generalize effectively. Future research in this area could \\nbenefit from addressing these limitations. In addition, by exploring different CNN architectures and variations, re-\\nsearchers may discover improved models with enhanced accuracy. Acquiring a more extensive and diverse dataset \\nthat encompasses various parking environments could also enhance the models' ability to generalize across diff erent \\nscenarios.  Furthermore, the investigation of alternative data preprocessing techniques such as image augmentation and feature extraction may lead to performance gains. While the models used in this research did not reach the desired \\nlevel of accuracy for integration into automated parking systems, this research highlights the positive impact of in-\\ncreasing the number of epochs on the AI model's accuracy in determining parking space occupancy from images. \\nDespite the limitations encountered, the study opens the door to more efficient parking management solutions. The \\ninsights gained from this research can inform future endeavors to develop more robust and accurate AI -based parking \\noccupancy detection systems, potentially revolutionizing the way parking spaces are managed and improving user experiences.  \\n \\nAcknowledgements  \\n \\nI would like to thank the staff at Eastchester High School for helping me throughout the process and guiding me \\nthrough the process of writing this paper. I would also like to thank my parents for supporting me throughout the entire \\nprocess.  \\n \\nReferences  \\n \\n[1] “Urban Development.” World Bank , www.worldbank.org/en/topic/urbandevelopment/overview. Accessed 28 \\nJune 2023. \\n[2] “68% of the World Population Projected to Live in Urban Areas by 2050, Says Un | UN Desa  Department of \\nEconomic and Social Affairs.” United Nations , www.un.org/development/desa/en/news/population/2018-\\nrevision -of-world -urbanization- prospects.html . Accessed 28 June 2023.  \\n[3] Noyes, Lexie. “Stop Wasting Time Searching for Parking. Park Smarter.” SpotHero Blog, 12 Dec. 2017, \\nblog.spothero.com/park -smarter -parking- search -time.  \\n \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n8\\n\"), Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 8}, page_content='[4] “Automated Parking System Market Projected to Achieve a Valuation of US$ 5.2 Billion by 2032, with Europe \\nLeading the Market Share at 42%.” GlobeNewswire News Room, 11 Apr. 2023, \\nwww.globenewswire.com/en/news -re lease/2023/04/11/2644888/0/en/Automated- Parking -System -Market -\\nprojected -to-achieve-a- valuation- of-US-5-2- billion -by-2032 -with-Europe -leading -the-market -share -at-42.html . \\n[5] “Automated Parking System Market Size, Share & Covid- 19 Impact Analysis, by Application Type \\n(Commercial Parking, Residential Parking), by Automation Level (Fully Automated, Semi -Automated), by \\nComponent Type (Hardware, Software), and Regional Forecasts, 2021- 2028.” Automated Parking System \\nMarket Size, Growth | Forecast, 2028, www.fortunebusinessinsights.com/automated- par king- system -market -\\n105486. Accessed 30 June 2023.  \\n[6] Solawetz, Jacob. “What Is YOLOv5? A Guide for Beginners.” What Is YOLOv5? A Guide for Beginners , \\nRoboslow, 29 June 2020, https://blog.roboflow.com/yolov5- improvements -and-evaluation/ . Accessed 6 July \\n2023.  \\n[7] Kathuria, Ayoosh. “How to Train Yolo V5 on a Custom Dataset.” Paperspace Blog, 10 Apr. 2023, \\nblog.\\npaperspace.com/train- yolov5- custom- data/ .  \\n[8] Jiang, Peiyuan, et al. A Review of Yolo Algorithm Developments , 2021 ( link).  \\n[9] “Yolo Algorithm for Object Detection Explained [+examples].” YOLO Algorithm for Object Detection \\nExplained [+Examples], www.v7labs.com/blog/yolo- object -detection . Accessed 30 June 2023.  \\n[10] “Introduction to Yolo Algorithm for Object Detection.” Section , www.section.io/engineering -\\neducation/introduction -to-yolo- algorithm -for-object -detection/ . Accessed 30 June 2023.  \\n[11] “What Is a Convolutional Neural Network?: 3 Things You Need to Know.” What Is a Convolutional Neural \\nNetwork? | 3 Things You Need to Know - MATLAB &amp; Simulink, \\nwww.mathworks.com/discovery/convolutional -neural -network -matlab.html . Accessed 3 July 2023.  \\n[12] Awati, Rahul. “What Are Convolutional Neural Networks?: Definition from TechTarget.” Enterprise AI, 24 \\nApr. 2023, www.techtarget.com/searchenterpriseai/definition/convolutional- neural -network.  \\n[13] Lihi  Gur Arie, PhD. “The Practical Guide for Object Detection with Yolov5 Algorithm.” Medium , 14 Feb. \\n2023, towardsdatascience.com/the- practical -guide -for-object -detection -with-yolov5 -algorithm -74c04aac4843 .  \\n[14] Solawetz, Jacob. “Mean Average Precision (MAP) in Object Detection.” Roboflow Blog, 25 Nov. 2022, \\nblog.roboflow.com/mean -average- precision/ .  \\n[15] Anchor Boxes for Object Detection - MATLAB &amp; Simulink, \\nwww.mathworks.com/help/vision/ug/anchor -boxes -for-object -detection.html . Accessed 6 July 2023..  \\n[16] Kukil. “Intersection over Union IOU in Object Detection Segmentation.” LearnOpenCV, 13 Feb. 2023, \\nlearnopencv.com/intersection -over-u nion-iou-in-object -detection -and-\\nsegmentation/#:~:text=Intersection%20Over%20Union%20(IoU)%20is,Ground%20Truth%20and%20Predictio\\nn%20region.  \\n[17] Hosang, Jan, et al. “A Convnet for Non -Maximum Suppression.” arXiv.Org , 8 Jan. 2016, \\nhttps://arxiv.org/pdf/1511.06437.pdf .  \\n[18] “Papers with Code - Non Maximum Suppression Explained.” Explained | Papers With Code , \\npaperswithcode.com/method/non- max imum-\\nsuppression#:~:text=Non%20Maximum%20Suppression%20is%20a,below%20a%20given%20probability%20\\nbound.  Accessed 6 July 2023.  \\n[19] Fessel, Kimberly, director. Never Forget Again! // Precision vs Recall with a Clear Example of Precision and \\nRecall. YouTube, YouTube, 1 Mar. 2021, \\nhttps://www.youtube.com/watch?v=qWfzIYCvBqo&amp;t=5s&amp;ab_channel=KimberlyFessel.  Accessed 8 \\nJuly 2023.  \\n[20] LILINOpenGitHub. “LILINOpenGitHub/Labeling- Tool : Yolo Ai Labeling Tool.” GitHub , \\ngithub.com/LILINOpenGitHub/Labeling- Tool . Accessed 20 July 2023.  \\n \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n9\\n'), Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 9}, page_content='[21] Alam, Mahbubul. “Data Normalization in Machine Learning.” Medium , 14 Dec. 2020, \\ntowardsdatascience.com/data- normalization -in-machine -learning -395fdec69d02 .  \\n[22] Ding, Xiangwu, and Ruidi Yang. Vehicle and Parking Space Detection Based on Improved YOLO ... - \\nIopscience, 2019, https://iopscience.iop.org/article/10.1088/1742 -6596/1325/1/012084/pdf .  \\n[23] Siddiqui, Shahan Yamin, et al. “Smart Occupancy Detection for Road Traffic Parking Using Deep Extreme \\nLearning Machine.” Journal of King Saud University - Computer and Information Sciences , 6 Feb. 2020, \\nwww.sciencedirect.com/science/article/pii/S1319157819313928 .  \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n10\\n')]\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1L27WlvyJIu"
      },
      "outputs": [],
      "source": [
        "#Step 05: Split the Extracted Data into Text Chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=20)\n",
        "\n",
        "text_chunks = text_splitter.split_documents(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Jq5TiVcyiu2",
        "outputId": "e3a09a42-00fc-4552-b116-a3e4d2281191"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(text_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o8aXL-Ryp9e",
        "outputId": "9451051e-798f-4904-a504-ba3b244fb16b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/drive/MyDrive/Data/Identifying_Parking_Lot_Occupancy_with_YOLOv5.pdf', 'page': 2}, page_content='the custom dataset. The YOLO algorithm is a deep learning -based object detection method known for its real -time \\ndetection capabilities [8][9][10]. It performs both object localization (identifying the location of one or more objects \\nin an image and drawing  a bounding box around it) and classification (naming the bounding boxes) simultaneously. \\nYOLO uses Convolutional Neural Networks (CNN) to detect images.  Convolutional Neural Networks (CNN) is a neural network that looks at a whole group of pixels in an image [11][12]. This allows for feature learning where the \\nmodel can analyze the image thoroughly allowing it to spot any features that will help to make a prediction. The \\ndarknet architecture of YOLOv5 supports various types of layers including CNN and pooling layers. CNNs employ \\nconvolutional layers to extract relevant features from the images such as edges, textures, and shapes associated with \\nparking spaces. Pooling layers in the CNN reduce the spatial dimensions of the feature map by combining the outputs \\nof neuron clusters at the previous layer into a single neuron in the next layer allowing for the model to intake the most \\nuseful information and leave out insignificant features in an image.  \\nDuring the training process, the YOLO model used loss functions to improve accuracy. YOLOv5’s loss \\nfunction is composed of three parts: box_loss, obj_loss, and cls_loss [13][6]. These loss functions are applied to max-\\nimize the objective of mean average precision, a measurement used to measure the performance of computer vision \\nmodels [14]. After every epoch, the model is tested on the validation dataset and an overall loss value is calculated. \\nThe training ends when the number of epochs allotted (300 and 50) is completed.  In order to detect objects, YOLO \\ndivides the input image into a n x n grid and draws bounding boxes along with probabilities of classified objects for \\neach grid cell. This approach allows for efficient and accurate object detection.   Anch or boxes are another important \\ncomponent in the training of the model [15]. Anchor boxes are a set of predefined bounding boxes of a certain height and width.  The size of the anchor boxes is typically based on the object size in the training dataset where  bigger \\nobjects in a training image would result in bigger anchor boxes. These boxes are tiled across the images and  capture \\nthe specific object classes to be detected which in this case is empty or occupied parking spaces.  \\nOnce the anchor boxes are scattered across the image, a metric such as Intersection Over Union (IoU) is used \\nto determine the probability of a certain object in an image. Intersection Over Union is a number that quantifies the \\ndegree of overlap between two  boxes [16].   The equation to compute the IoU is the area of overlap of both bounding \\nboxes over the area of union (the ground truth bounding box area + predicted bounding box area - an area of intersec-\\ntion of both bounding boxes). A number between 0 and 1 is calculated where a higher value indicates a greater overlap \\narea and a higher accuracy.  \\nAt this point, the model has many bounding boxes shown on the image which makes the image messy and \\nunorganized. Therefore, Non -Maximum Suppression (NMS) method is used to help combine bouncing boxes, but \\nalso remove bounding boxes that have an IoU value lower than the NMS threshold [17][18]. NMS selects a single \\nbounding box with the highest confidence score and combines other bounding boxes that have a high overlap with it. \\nNMS helps in reducing duplicate detections and improves the final output by the mo del.  \\nThe model learning procedure consists of the creation of the dataset, preprocessing the data, splitting the \\ndataset, and training the model. As previously stated, I created my own dataset. This way, I ensured that the model \\nwas using the most accurate imag es to train with minimal human error. Once all necessary files were properly uploaded \\ninto the C olab notebook, I started the training for 50 and 300 epochs. It took around 2- 3 hours for both to finish, and \\nI downloaded all the results produced by the model. Once the training process was completed for both models, I \\nrecorded the different predictions produced.  \\n \\nResults and Discussion  \\n Once I trained the model, I went outside and took a video of a car going in and out of a parking space to see if the \\nmodel could properly detect the empty and occupied parking spaces. The model trained for 300 epochs performed \\nsignificantly better than the  model with 50 epochs when tested on the video and images.  \\n \\nVolume 12 Issue 4 (2023) \\nISSN: 2167-1907\\nwww.JSR.org\\n3')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#get the third chunk\n",
        "text_chunks[2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step: Create Embeddings for each of the Text Chunk using Pathway\n",
        "class InputSchema(pw.Schema):\n",
        "    doc: str\n",
        "\n",
        "# Create DataFrame from text_chunks\n",
        "text_df = pd.DataFrame({\"doc\": [chunk.page_content for chunk in text_chunks]})\n",
        "documents = pw.debug.table_from_pandas(text_df, schema=InputSchema)"
      ],
      "metadata": {
        "id": "__pwRIaY85uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 06:Downlaod the Embeddings\n",
        "\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "embedder = embedders.SentenceTransformerEmbedder(\n",
        "    embedding_model, call_kwargs={\"show_progress_bar\": False}\n",
        ")\n",
        "embedding_dimension: int = embedder.get_embedding_dimension()"
      ],
      "metadata": {
        "id": "gYOy3dol9nA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_dimension)\n",
        "index = default_vector_document_index(\n",
        "    documents.doc, documents, embedder=embedder, dimensions=embedding_dimension\n",
        ")"
      ],
      "metadata": {
        "id": "09zkH_9f_hqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf128be7-668a-4191-bc37-25c091814e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJbn_hjzznhm"
      },
      "outputs": [],
      "source": [
        "# #Step 08: Create Embeddings for each of the Text Chunk\n",
        "# vector_store = FAISS.from_documents(text_chunks, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9Y5Va538RDL",
        "outputId": "7cfe0a5e-f318-4b81-da66-9ade768e97d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /content/drive/MyDrive/Model/mistral-7b-instruct-v0.1.Q4_K_M (1).gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens cache size = 259\n",
            "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: max token length = 48\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
            ".................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =    18.50 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ],
      "source": [
        "#Import Model\n",
        "llm = LlamaCpp(\n",
        "    streaming = True,\n",
        "    model_path=\"/content/drive/MyDrive/Model/mistral-7b-instruct-v0.1.Q4_K_M (1).gguf\",\n",
        "    temperature=0.75,\n",
        "    top_p=1,\n",
        "    verbose=True,\n",
        "    n_ctx=4096\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using pathway vector store client"
      ],
      "metadata": {
        "id": "4jrXSnuA_Wra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --prefer-binary pathway\n",
        "!pip install pathway[xpack-llm]\n",
        "!pip install -U langchain-huggingface"
      ],
      "metadata": {
        "id": "xOUEEXrnkN9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U langchain_community\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from pathway.xpacks.llm.vector_store import VectorStoreServer\n",
        "from langchain_community.vectorstores import PathwayVectorClient"
      ],
      "metadata": {
        "id": "Y9SV9QW9Awhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "AOlSv2tJADFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pw.io.fs.read(\n",
        "    \"/content/drive/MyDrive/Data\",\n",
        "    format=\"binary\",\n",
        "    mode=\"streaming\",\n",
        "    with_metadata=True,\n",
        ")\n",
        "splitter = CharacterTextSplitter()\n"
      ],
      "metadata": {
        "id": "aSvcJLRJA0AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your Localtunnel URL\n",
        "localtunnel_url = \"https://curvy-lions-invite.loca.lt\"\n",
        "host = localtunnel_url.replace(\"http://\", \"\").replace(\"https://\", \"\").split(\":\")[0]\n",
        "port = \"80\"\n",
        "\n",
        "server = VectorStoreServer.from_langchain_components(\n",
        "    data, embedder=embeddings, splitter=splitter\n",
        ")\n",
        "\n",
        "server.run_server(host, port=port, with_cache=True, cache_backend=pw.persistence.Backend.filesystem(\"./Cache\"), threaded=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2m3zFnNBMxN",
        "outputId": "ab22db6a-5c2a-4b47-eb18-33e140f65be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Thread(VectorStoreServer, started 133338277119552)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = PathwayVectorClient(url=\"https://demo-document-indexing.pathway.stream\")"
      ],
      "metadata": {
        "id": "HAJUpJnfBlRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG pipeline in LangChain"
      ],
      "metadata": {
        "id": "18wbmbUnG6hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "retriever = client.as_retriever()\n",
        "\n",
        "template = \"\"\"\n",
        "You are smart assistant that helps users with their documents on Google Drive and Sharepoint.\n",
        "Given a context, respond to the user question.\n",
        "CONTEXT:\n",
        "{context}\n",
        "QUESTION: {question}\n",
        "YOUR ANSWER:\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n"
      ],
      "metadata": {
        "id": "9V3Zg851HeKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"Hi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "LjABKz-8MmL-",
        "outputId": "bebf132f-c042-44b1-9ccf-dc6ef9220e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3952.36 ms\n",
            "llama_print_timings:      sample time =       8.08 ms /    13 runs   (    0.62 ms per token,  1608.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =  272033.28 ms /   527 tokens (  516.19 ms per token,     1.94 tokens per second)\n",
            "llama_print_timings:        eval time =    8362.42 ms /    12 runs   (  696.87 ms per token,     1.43 tokens per second)\n",
            "llama_print_timings:       total time =  280477.44 ms /   539 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hello! How can I assist you with your documents today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#USING pathway Query table and Query retriever setup"
      ],
      "metadata": {
        "id": "EMu-7iMbKBxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the query table\n",
        "query_df = pd.DataFrame({\"query\": [\"What is linear regression model\"]})\n",
        "query = pw.debug.table_from_pandas(query_df)"
      ],
      "metadata": {
        "id": "XlfFGjyxKAno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step: Define RetrievalQA using Pathway's retriever setup\n",
        "# result = query.select(\n",
        "#     question=query.query,\n",
        "#     result=answer_with_geometric_rag_strategy_from_index(\n",
        "#         query.query,\n",
        "#         index,\n",
        "#         documents.doc,\n",
        "#         llm,\n",
        "#         n_starting_documents=2,\n",
        "#         factor=2,\n",
        "#         max_iterations=4,\n",
        "#         strict_prompt=True,\n",
        "#     ),\n",
        "# )\n",
        "result = query.select(\n",
        "    question=query.query,\n",
        "    result=pw.apply(\n",
        "        lambda q: answer_with_geometric_rag_strategy_from_index(\n",
        "            q,\n",
        "            index,\n",
        "            documents.doc,\n",
        "            llm,\n",
        "            n_starting_documents=2,\n",
        "            factor=2,\n",
        "            max_iterations=4,\n",
        "            strict_prompt=True,\n",
        "        ),\n",
        "        query.query\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "C4XCq9tfK77F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interactive Loop for user queries and answer by the LLM"
      ],
      "metadata": {
        "id": "wkVSIEGaXPH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Input Prompt: \")\n",
        "    if user_input == 'exit':\n",
        "        print('Exiting')\n",
        "        sys.exit()\n",
        "    if user_input == '':\n",
        "        continue\n",
        "\n",
        "    # Update the query table with user input\n",
        "    query_df = pd.DataFrame({\"query\": [user_input]})\n",
        "    query = pw.debug.table_from_pandas(query_df)\n",
        "\n",
        "    # Execute the query using the new retriever setup\n",
        "    result = query.select(\n",
        "        question=query.query,\n",
        "        result=pw.apply(\n",
        "            lambda q: answer_with_geometric_rag_strategy_from_index(\n",
        "                q,\n",
        "                index,\n",
        "                documents.doc,\n",
        "                llm,\n",
        "                n_starting_documents=2,\n",
        "                factor=2,\n",
        "                max_iterations=4,\n",
        "                strict_prompt=True,\n",
        "            ),\n",
        "            query.query\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Extract and print the result\n",
        "    print(f\"Answer: {result['result']}\")\n",
        "    result1 = pd.DataFrame(result)\n",
        "    print(result1)\n",
        "\n",
        "\n",
        "# while True:\n",
        "#     user_input = input(\"Input Prompt: \")\n",
        "#     if user_input == 'exit':\n",
        "#         print('Exiting')\n",
        "#         sys.exit()\n",
        "#     if user_input == '':\n",
        "#         continue\n",
        "\n",
        "#     # Update the query table with user input\n",
        "#     query_df = pd.DataFrame({\"query\": [user_input]})\n",
        "#     query = pw.debug.table_from_pandas(query_df)\n",
        "\n",
        "#     # Execute the query\n",
        "#     result = query.select(\n",
        "#         question=query.query,\n",
        "#         result=answer_with_geometric_rag_strategy_from_index(\n",
        "#             query.query,\n",
        "#             index,\n",
        "#             documents.doc,\n",
        "#             llm,\n",
        "#             n_starting_documents=2,\n",
        "#             factor=2,\n",
        "#             max_iterations=4,\n",
        "#             strict_prompt=True,\n",
        "#         ),\n",
        "#     )\n",
        "\n",
        "#     # Extract and print the result\n",
        "#     print(f\"Answer: {result['result']}\")\n",
        "\n",
        "\n",
        "# while True:\n",
        "#     user_input = input(\"Input Prompt: \")\n",
        "#     if user_input == 'exit':\n",
        "#         print('Exiting')\n",
        "#         sys.exit()\n",
        "#     if user_input == '':\n",
        "#         continue\n",
        "\n",
        "#     # Update the query table with user input\n",
        "#     query_df = pd.DataFrame({\"query\": [user_input]})\n",
        "#     query = pw.debug.table_from_pandas(query_df)\n",
        "\n",
        "#     # Execute the query using the new retriever setup\n",
        "#     result = query.select(\n",
        "#         question=query.query,\n",
        "#         result=pw.apply(\n",
        "#             lambda q: answer_with_geometric_rag_strategy_from_index(\n",
        "#               query.query,\n",
        "#               index,\n",
        "#               documents.doc,\n",
        "#               llm,\n",
        "#               n_starting_documents=2,\n",
        "#               factor=2,\n",
        "#               max_iterations=4,\n",
        "#               strict_prompt=True,\n",
        "#           ),\n",
        "#           query.query\n",
        "#       ),\n",
        "#   )\n",
        "\n",
        "#     # Collect and print the result\n",
        "#     pw.debug.compute_and_print(result)\n",
        "#     # print(f\"Answer: {result['result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "IIbZZpDEYeTQ",
        "outputId": "c03700d3-cc86-404e-d66f-4cd86b48ddd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Prompt: hi\n",
            "Answer: <table1>.result\n",
            "                   0\n",
            "0  <table1>.question\n",
            "1    <table1>.result\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-67f7c9498b29>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input Prompt: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Exiting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Vpb_w-i94Th",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "61924263-8bd5-4971-d08a-728de4ece8f3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataIndex' object has no attribute 'as_retriever'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-eaa59dc22890>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetrievalQA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_chain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"stuff\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataIndex' object has no attribute 'as_retriever'"
          ]
        }
      ],
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=index.as_retriever(search_kwargs={\"k\": 2}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DWiBe3cENZB"
      },
      "outputs": [],
      "source": [
        "query = \"What is linear regression model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "mdFYMQfR_gzI",
        "outputId": "492b27f0-f945-4fd3-8b3e-15ea2b4447e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The linear regression model is a statistical method for modeling the relationship between a dependent variable and one or more independent variables, commonly referred to as predictors or explanatory variables. In this paper, the linear regression model is used as a starting point to derive estimators for the variance-covariance matrix of the errors in certain structural change models.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa.run(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl_4JdUatnTQ",
        "outputId": "e4c2b67d-3bf9-41bb-a7a0-1d3584d93e0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:  It is a statistical method used to analyze the linear relationship between two or more variables. In this case, it is used to estimate the coefficients of a linear regression model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:  sandwich provides various functions for estimating the covariance matrix. The most commonly used ones are vcovHAC and vcovHC. These functions can take different weighting schemes, including kernel-based HAC estimation with automatic bandwidth selection based on weightsAndrews andbwAndrews. Other functions like weightsLumley provide different weighting schemes, such as truncated and smoothed weights, which are useful in certain applications. In econometric analyses, these functions are used to compute partial t-tests for assessing the significance of a parameter. The choice of estimator depends on the presence of heteroscedasticity and autocorrelation in the errors.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "while True:\n",
        "  user_input = input(f\"Input Prompt: \")\n",
        "  if user_input == 'exit':\n",
        "    print('Exiting')\n",
        "    sys.exit()\n",
        "  if user_input == '':\n",
        "    continue\n",
        "  result = qa({'query': user_input})\n",
        "  print(f\"Answer: {result['result']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}